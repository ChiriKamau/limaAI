{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#start\n"
      ],
      "metadata": {
        "id": "6F8NDZEtr3Ri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "WGRP4b4et-Hz",
        "outputId": "d857a8f9-fcfa-47b2-8120-a576d5c673ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1408506528.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    132\u001b[0m   )\n\u001b[1;32m    133\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define paths\n",
        "csv_image_mapping = [\n",
        "        {\n",
        "        'csv_path': '/content/drive/MyDrive/Tomato_dataset/phone1(ripe)/phone1(ripe).csv',\n",
        "        'image_dir': '/content/drive/MyDrive/Tomato_dataset/phone1(ripe)'\n",
        "    },\n",
        "    {\n",
        "        'csv_path': '/content/drive/MyDrive/Tomato_dataset/Phone1(green)/phone1(green).csv',\n",
        "        'image_dir': '/content/drive/MyDrive/Tomato_dataset/Phone1(green)'\n",
        "    },\n",
        "    {\n",
        "        'csv_path': '/content/drive/MyDrive/Tomato_dataset/phone2(batch1)/annotations/phone2(batch1).csv',\n",
        "        'image_dir': '/content/drive/MyDrive/Tomato_dataset/phone2(batch1)'\n",
        "    },\n",
        "    {\n",
        "        'csv_path': '/content/drive/MyDrive/Tomato_dataset/phone2(batch2)/annotations/phone2(batch2).csv',\n",
        "        'image_dir': '/content/drive/MyDrive/Tomato_dataset/phone2(batch2)'\n",
        "    }\n",
        "]\n",
        "output_dir = '/content/drive/MyDrive/Tomato_dataset/cnn_crops'"
      ],
      "metadata": {
        "id": "wQ7xEhm8uWfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2zNsjKErvRc",
        "outputId": "fe062bcc-83e8-467b-f858-64d39cbc5af2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4451/4451 [09:47<00:00,  7.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Cropped datasets saved to cropped_dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from multiprocessing.dummy import Pool as ThreadPool\n",
        "import tqdm\n",
        "\n",
        "# -----------------------------\n",
        "# CONFIG\n",
        "# -----------------------------\n",
        "output_dir = 'cropped_dataset'  # where crops will be saved\n",
        "\n",
        "ripe_labels = ['R.healthy', 'R.lateblight', 'R.spots', 'R.pests', 'R.ber']\n",
        "green_labels = ['G.healthy', 'G.lateblight', 'G.spots', 'G.pests', 'G.ber']\n",
        "\n",
        "# Example: list of dictionaries mapping CSV to image directories\n",
        "# csv_image_mapping = [{'csv_path': 'path/to/csv1.csv', 'image_dir': 'path/to/images1'},\n",
        "#                      {'csv_path': 'path/to/csv2.csv', 'image_dir': 'path/to/images2'}]\n",
        "\n",
        "# -----------------------------\n",
        "# LOAD AND FILTER DATA\n",
        "# -----------------------------\n",
        "dfs = [pd.read_csv(m['csv_path']).assign(image_dir=m['image_dir']) for m in csv_image_mapping]\n",
        "data = pd.concat(dfs, ignore_index=True)[\n",
        "    ['image_name','label_name','bbox_x','bbox_y','bbox_width','bbox_height','image_dir']\n",
        "]\n",
        "data = data[data['label_name'].isin(ripe_labels + green_labels)]\n",
        "\n",
        "# -----------------------------\n",
        "# CREATE OUTPUT DIRECTORIES\n",
        "# -----------------------------\n",
        "for ripeness in ['ripe', 'green']:\n",
        "    for split in ['train', 'val']:\n",
        "        labels = ripe_labels if ripeness == 'ripe' else green_labels\n",
        "        for label in labels:\n",
        "            os.makedirs(os.path.join(output_dir, ripeness, split, label.replace('.', '_')), exist_ok=True)\n",
        "\n",
        "# -----------------------------\n",
        "# TRAIN/VAL SPLIT\n",
        "# -----------------------------\n",
        "unique_images = data['image_name'].unique()\n",
        "train_images, val_images = train_test_split(unique_images, test_size=0.2, random_state=42)\n",
        "train_set, val_set = set(train_images), set(val_images)\n",
        "\n",
        "# -----------------------------\n",
        "# PREPARE ROWS FOR THREADING\n",
        "# -----------------------------\n",
        "rows = [(r['image_dir'], r['image_name'], r['label_name'], r['bbox_x'], r['bbox_y'], r['bbox_width'], r['bbox_height'])\n",
        "        for r in data.to_dict(orient='records')]\n",
        "\n",
        "# -----------------------------\n",
        "# PROCESS FUNCTION\n",
        "# -----------------------------\n",
        "def process_row(row):\n",
        "    image_dir, image_name, label_name, x, y, w, h = row\n",
        "    img_path = os.path.join(image_dir, image_name)\n",
        "    if not os.path.exists(img_path):\n",
        "        return\n",
        "    img = cv2.imread(img_path)\n",
        "    if img is None:\n",
        "        return\n",
        "    x, y, w, h = map(int, (x, y, w, h))\n",
        "    crop = img[y:y+h, x:x+w]\n",
        "    if crop.size == 0:\n",
        "        return\n",
        "    crop = cv2.resize(crop, (224, 224))\n",
        "    ripeness = 'ripe' if label_name.startswith('R') else 'green'\n",
        "    label_dir = label_name.replace('.', '_')\n",
        "    split = 'train' if image_name in train_set else 'val'\n",
        "    save_path = os.path.join(output_dir, ripeness, split, label_dir, f\"{image_name.replace('.jpg', f'_{x}_{y}.jpg')}\")\n",
        "    cv2.imwrite(save_path, crop)\n",
        "\n",
        "# -----------------------------\n",
        "# PARALLEL EXECUTION\n",
        "# -----------------------------\n",
        "num_threads = 8  # Adjust depending on your CPU\n",
        "with ThreadPool(num_threads) as pool:\n",
        "    list(tqdm.tqdm(pool.imap(process_row, rows), total=len(rows)))\n",
        "\n",
        "print(f\"✅ Cropped datasets saved to {output_dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Base dataset path\n",
        "base_dir = \"/content/drive/MyDrive/Tomato_dataset/cnn_crops\"\n",
        "backup_dir = os.path.join(base_dir, \"removed_classes\")\n",
        "\n",
        "# Ensure backup folder exists\n",
        "os.makedirs(backup_dir, exist_ok=True)\n",
        "\n",
        "# Folders to move\n",
        "to_move = [\n",
        "    f\"{base_dir}/ripe/train/R_pests\",\n",
        "    f\"{base_dir}/ripe/val/R_pests\",\n",
        "    f\"{base_dir}/green/train/G_pests\",\n",
        "    f\"{base_dir}/green/val/G_pests\",\n",
        "]\n",
        "\n",
        "# Move images\n",
        "for folder in to_move:\n",
        "    if os.path.exists(folder):\n",
        "        # Get all files in folder\n",
        "        for filename in os.listdir(folder):\n",
        "            src_path = os.path.join(folder, filename)\n",
        "            dst_path = os.path.join(backup_dir, f\"{os.path.basename(folder)}_{filename}\")\n",
        "            shutil.move(src_path, dst_path)\n",
        "        print(f\"✅ Moved images from: {folder} → {backup_dir}\")\n",
        "        # Optionally remove the empty folder\n",
        "        os.rmdir(folder)\n",
        "    else:\n",
        "        print(f\"⚠️ Folder not found: {folder}\")\n",
        "\n",
        "print(\"\\n✨ Done! R_pests and G_pests images moved to 'removed_classes'.\")\n"
      ],
      "metadata": {
        "id": "_sW0GjkMWB2s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}