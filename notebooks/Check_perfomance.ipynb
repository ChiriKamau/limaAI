{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üçÖ Tomato Model Performance Evaluation\n",
        "\n",
        "**Welcome to the Model Evaluation Notebook!**\n",
        "\n",
        "This notebook evaluates two CNN models and two MobileNetV2 transfer learning models for tomato disease classification, stored in `.keras` format on Google Drive. The models target:\n",
        "\n",
        "- **Ripe Model**: 3 classes (*Blossom End Rot* ('R_ber'), *Bacterial Spots* ('R_spots'), *Healthy* ('R_healthy'))\n",
        "- **Green Model**: 4 classes (*Blossom End Rot* ('G_ber'), *Bacterial Spots* ('G_spots'), *Late Blight* ('G_lateblight'), *Healthy* ('G_healthy'))\n",
        "\n",
        "**Goal**: Assess performance using accuracy, precision, recall, F1-score, and confusion matrices, focusing on minority classes (e.g., 'G_lateblight') due to dataset imbalance. Confusion matrix heatmaps visualize class-specific performance to compare CNN and transfer learning models.\n",
        "\n",
        "**Steps**: Load validation data, load models, compute metrics, visualize results, and summarize model performance."
      ],
      "metadata": {
        "id": "aaTmz9hUIP9h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries and Set Up Validation Data\n",
        "\n",
        "This cell imports libraries for model evaluation, visualization, and data loading from Google Drive. It mounts Google Drive to access the tomato dataset and defines validation data generators for ripe and green splits.\n",
        "\n",
        "The generators load images (224x224, batch size 16) from the validation directories without augmentation, ensuring consistent evaluation. Class indices are printed to confirm the dataset structure (3 classes for ripe, 4 for green)."
      ],
      "metadata": {
        "id": "gnwYlo_zINcG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define paths\n",
        "output_dir = '/content/drive/MyDrive/Tomato_dataset/cnn_crops'\n",
        "ripe_val_dir = os.path.join(output_dir, 'ripe/val')\n",
        "green_val_dir = os.path.join(output_dir, 'green/val')\n",
        "\n",
        "# Data generators for validation\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "ripe_val_gen = val_datagen.flow_from_directory(\n",
        "    ripe_val_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=16,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False  # Important for consistent evaluation\n",
        ")\n",
        "\n",
        "green_val_gen = val_datagen.flow_from_directory(\n",
        "    green_val_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=16,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Print class indices\n",
        "print(\"Ripe validation classes:\", ripe_val_gen.class_indices)\n",
        "print(\"Green validation classes:\", green_val_gen.class_indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_H92o5zsITEt",
        "outputId": "1b3d3211-aa56-4c44-e449-d6229ce6c50f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Found 384 images belonging to 3 classes.\n",
            "Found 946 images belonging to 4 classes.\n",
            "Ripe validation classes: {'R_ber': 0, 'R_healthy': 1, 'R_spots': 2}\n",
            "Green validation classes: {'G_ber': 0, 'G_healthy': 1, 'G_lateblight': 2, 'G_spots': 3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Trained Models\n",
        "\n",
        "This cell loads the trained CNN and MobileNetV2 models from `.keras` files stored in Google Drive. It includes two CNN models (for ripe and green tomatoes) and two transfer learning models (MobileNetV2) for comparison.\n",
        "\n",
        "The models are loaded using `tf.keras.models.load_model`, ensuring they‚Äôre ready for evaluation on the validation sets. Paths match those used during training for consistency."
      ],
      "metadata": {
        "id": "HfZ_paMJIwRm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model paths\n",
        "ripe_cnn_path = '/content/drive/MyDrive/Tomato_dataset/models/ripe_cnn(v2).keras'\n",
        "green_cnn_path = '/content/drive/MyDrive/Tomato_dataset/models/green_cnn(v2).keras'\n",
        "ripe_transfer_path = '/content/drive/MyDrive/Tomato_dataset/models/ripe_mobilenet(v2).keras'\n",
        "green_transfer_path = '/content/drive/MyDrive/Tomato_dataset/models/green_mobilenet(v2).keras'\n",
        "\n",
        "# Load models\n",
        "ripe_cnn_model = tf.keras.models.load_model(ripe_cnn_path)\n",
        "green_cnn_model = tf.keras.models.load_model(green_cnn_path)\n",
        "ripe_transfer_model = tf.keras.models.load_model(ripe_transfer_path)\n",
        "green_transfer_model = tf.keras.models.load_model(green_transfer_path)\n",
        "\n",
        "print(\"All models loaded successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAaLrbYtI9sx",
        "outputId": "28ede54a-fe83-4cb3-a9e9-586161fd9d7a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 12 variables whereas the saved optimizer has 22 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All models loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate Model Performance\n",
        "\n",
        "This cell evaluates each model on its respective validation set, computing accuracy, precision, recall, and F1-score per class. It collects true labels and predictions from the validation generators, ensuring `shuffle=False` for alignment.\n",
        "\n",
        "The `classification_report` from scikit-learn provides detailed metrics, emphasizing minority classes (e.g., 'R_spots', 'G_lateblight'). Results are printed for both CNN and transfer learning models to compare performance."
      ],
      "metadata": {
        "id": "8giQOapmJN0w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to evaluate a model\n",
        "def evaluate_model(model, val_gen, model_name):\n",
        "    # Get true labels and predictions\n",
        "    val_gen.reset()  # Reset generator to start\n",
        "    y_true = val_gen.classes\n",
        "    y_pred = model.predict(val_gen, verbose=1)\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "    # Print classification report\n",
        "    print(f\"\\nClassification Report for {model_name}:\")\n",
        "    print(classification_report(y_true, y_pred_classes, target_names=val_gen.class_indices.keys()))\n",
        "\n",
        "    return y_true, y_pred_classes\n",
        "\n",
        "# Evaluate models\n",
        "ripe_cnn_true, ripe_cnn_pred = evaluate_model(ripe_cnn_model, ripe_val_gen, \"Ripe CNN\")\n",
        "green_cnn_true, green_cnn_pred = evaluate_model(green_cnn_model, green_val_gen, \"Green CNN\")\n",
        "ripe_transfer_true, ripe_transfer_pred = evaluate_model(ripe_transfer_model, ripe_val_gen, \"Ripe MobileNetV2\")\n",
        "green_transfer_true, green_transfer_pred = evaluate_model(green_transfer_model, green_val_gen, \"Green MobileNetV2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 932
        },
        "id": "r9LMkpNHJRkI",
        "outputId": "36128056-0234-45fb-8b58-e24757f7e87d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 4s/step\n",
            "\n",
            "Classification Report for Ripe CNN:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       R_ber       0.67      0.45      0.54        80\n",
            "   R_healthy       0.65      0.66      0.66       194\n",
            "     R_spots       0.39      0.46      0.42       110\n",
            "\n",
            "    accuracy                           0.56       384\n",
            "   macro avg       0.57      0.53      0.54       384\n",
            "weighted avg       0.58      0.56      0.57       384\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m60/60\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 4s/step\n",
            "\n",
            "Classification Report for Green CNN:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       G_ber       0.40      0.20      0.26        41\n",
            "   G_healthy       0.58      0.79      0.67       481\n",
            "G_lateblight       0.25      0.61      0.35        41\n",
            "     G_spots       0.50      0.22      0.31       383\n",
            "\n",
            "    accuracy                           0.53       946\n",
            "   macro avg       0.43      0.45      0.40       946\n",
            "weighted avg       0.53      0.53      0.49       946\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Input 0 of layer \"functional_1\" is incompatible with the layer: expected shape=(None, 160, 160, 3), found shape=(16, 224, 224, 3)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-163279207.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mripe_cnn_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mripe_cnn_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mripe_cnn_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mripe_val_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Ripe CNN\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mgreen_cnn_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgreen_cnn_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgreen_cnn_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgreen_val_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Green CNN\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mripe_transfer_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mripe_transfer_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mripe_transfer_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mripe_val_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Ripe MobileNetV2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mgreen_transfer_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgreen_transfer_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgreen_transfer_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgreen_val_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Green MobileNetV2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-163279207.py\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(model, val_gen, model_name)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mval_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Reset generator to start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0my_pred_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/layers/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mspec_dim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mspec_dim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m                         raise ValueError(\n\u001b[0m\u001b[1;32m    246\u001b[0m                             \u001b[0;34mf'Input {input_index} of layer \"{layer_name}\" is '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m                             \u001b[0;34m\"incompatible with the layer: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"functional_1\" is incompatible with the layer: expected shape=(None, 160, 160, 3), found shape=(16, 224, 224, 3)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize Confusion Matrices\n",
        "\n",
        "This cell creates confusion matrix heatmaps for each model to visualize classification performance. Using `confusion_matrix` from scikit-learn, it compares true vs. predicted labels for the validation sets.\n",
        "\n",
        "Heatmaps are plotted with `seaborn` for ripe (3 classes) and green (4 classes) models, highlighting misclassifications, especially for minority classes like 'G_lateblight'. These visuals help compare CNN and transfer learning models."
      ],
      "metadata": {
        "id": "8xIvppXMJzIP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to plot confusion matrix\n",
        "def plot_confusion_matrix(y_true, y_pred, class_names, title):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.show()\n",
        "\n",
        "# Plot confusion matrices\n",
        "plot_confusion_matrix(ripe_cnn_true, ripe_cnn_pred, list(ripe_val_gen.class_indices.keys()), \"Ripe CNN Confusion Matrix\")\n",
        "plot_confusion_matrix(green_cnn_true, green_cnn_pred, list(green_val_gen.class_indices.keys()), \"Green CNN Confusion Matrix\")\n",
        "plot_confusion_matrix(ripe_transfer_true, ripe_transfer_pred, list(ripe_val_gen.class_indices.keys()), \"Ripe MobileNetV2 Confusion Matrix\")\n",
        "plot_confusion_matrix(green_transfer_true, green_transfer_pred, list(green_val_gen.class_indices.keys()), \"Green MobileNetV2 Confusion Matrix\")"
      ],
      "metadata": {
        "id": "yqQkpFyQKimN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compare Model Performance\n",
        "\n",
        "This cell summarizes the performance of CNN and MobileNetV2 models. It compares macro-averaged F1-scores from the classification reports to assess overall performance, with a focus on minority classes (e.g., 'R_spots', 'G_lateblight').\n",
        "\n",
        "Key observations include which model better handles imbalanced classes and whether transfer learning outperforms the custom CNN. Results guide model selection for deployment or further tuning."
      ],
      "metadata": {
        "id": "uBsBCS3gLsDM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manual comparison based on classification reports\n",
        "print(\"\\nModel Comparison Summary:\")\n",
        "print(\"1. Ripe Models:\")\n",
        "print(\"- CNN: Check F1-scores for 'R_spots' (minority class) in classification report.\")\n",
        "print(\"- MobileNetV2: Likely better for minority classes due to pre-trained weights.\")\n",
        "print(\"2. Green Models:\")\n",
        "print(\"- CNN: Check F1-scores for 'G_lateblight' and 'G_ber' (minority classes).\")\n",
        "print(\"- MobileNetV2: Expected to generalize better due to ImageNet features.\")\n",
        "print(\"\\nReview confusion matrices to identify misclassification patterns.\")\n",
        "print(\"Choose the model with higher macro F1-score and better minority class performance.\")s"
      ],
      "metadata": {
        "id": "MlN8IgkeL76z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}